<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>3a99e2cb45bb41248a7c5db3c647ced7</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<div class="cell markdown" id="07ee0dc1">
<p>#1- Project Background</p>
<p>This notebook is part of the practical coursework in the <strong>KDD
Course Lab</strong> at the <strong>Arab International University
(AIU)</strong>.</p>
<ul>
<li><strong>Student:</strong> MHD ZAID AL NAHHAS</li>
<li><strong>Instructor:</strong> Eng. RAGHAD ARAB</li>
</ul>
<p>This work extends the analysis from the notebook "<strong>DDoS
Detection using Machine Learning</strong>" by <strong>RAKIB HOSSAIN
SAJIB</strong>. This notebook focuses on exploring different encoders
and scalers with the KNN model, performing detailed evaluation and
tuning, and also training and optimizing a Decision Tree model,
including the application of SMOTE to address class imbalance.</p>
<h2 id="dataset-information">Dataset Information</h2>
<p>The dataset used in this notebook is <strong>CIC-DDoS2019</strong>,
an academic intrusion detection dataset available on Kaggle.</p>
<ul>
<li><strong>Original Authors:</strong> Dr. Iman Sharafaldin, Dr. Saqib
Hakak, Dr. Arash Habibi Lashkari, Dr. Ali Ghorbani. (Please cite their
original paper.)</li>
<li><strong>Description:</strong> The dataset contains an extended set
of Distributed Denial of Service attacks, primarily using amplification
through reflection. It shares features with other CIC NIDS datasets
(IDS2017, IDS2018, and DoS2017).</li>
<li><strong>Dataset Versions:</strong>
<ul>
<li><strong>V0:</strong> Base dataset in CSV format.</li>
<li><strong>V1:</strong> CSVs with corrected extreme class imbalance
(attack:benign ratio adjusted to 9:1).</li>
<li><strong>V2:</strong> Cleaned data converted to parquet files.</li>
<li><strong>V3:</strong> Reorganized for storage efficiency, keeping
original CSVs in V1/V2.</li>
</ul></li>
<li><strong>Clean Version (Parquet):</strong> Data types are correctly
set, with no missing information or duplicate records.</li>
<li><strong>Note:</strong> A previous analysis using an ensemble OneR
model achieved a 0.991 AUROC, suggesting the dataset may be relatively
easy to separate malicious from benign traffic globally.</li>
<li><strong>License:</strong> CC BY-NC-SA 4.0</li>
<li><strong>Expected Update Frequency:</strong> Never</li>
<li><strong>Tags:</strong> Internet, Tabular, Research, Cyber Security,
Tabular Classification</li>
<li><strong>File Format:</strong> Available in parquet format, which is
binary, tabular, and optimized for loading with
<code>pd.read_parquet</code> (requires <code>pyarrow</code> or
<code>fastparquet</code>).</li>
</ul>
<h3 id="dataset-files-version-3">Dataset Files (Version 3)</h3>
<p>The dataset consists of 17 parquet files:</p>
<ul>
<li>DNS-testing.parquet</li>
<li>LDAP-testing.parquet</li>
<li>LDAP-training.parquet</li>
<li>MSSQL-testing.parquet</li>
<li>MSSQL-training.parquet</li>
<li>NTP-testing.parquet</li>
<li>NetBIOS-testing.parquet</li>
<li>NetBIOS-training.parquet</li>
<li>Portmap-training.parquet</li>
<li>SNMP-testing.parquet</li>
<li>Syn-testing.parquet</li>
<li>Syn-training.parquet</li>
<li>TFTP-testing.parquet</li>
<li>UDP-testing.parquet</li>
<li>UDP-training.parquet</li>
<li>UDPLag-testing.parquet</li>
<li>UDPLag-training.parquet</li>
</ul>
</div>
<section id="training-and-optimizing-a-decision-tree-model"
class="cell markdown" id="0e147df6">
<h2>Training and Optimizing a Decision Tree Model</h2>
<p>In this section, we will train a Decision Tree model on the
preprocessed data and then fine-tune its hyperparameters using
GridSearchCV to find the optimal configuration.</p>
</section>
<section id="training-the-initial-decision-tree-model"
class="cell markdown" id="e10c8f6d">
<h3>Training the Initial Decision Tree Model</h3>
</section>
<div class="cell code"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2025-08-16T17:47:18.002898Z&quot;,&quot;iopub.status.busy&quot;:&quot;2025-08-16T17:47:18.002661Z&quot;,&quot;iopub.status.idle&quot;:&quot;2025-08-16T17:47:18.857132Z&quot;,&quot;shell.execute_reply&quot;:&quot;2025-08-16T17:47:18.855951Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2025-08-16T17:47:18.002880Z&quot;}"
id="c9ee0529">
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeClassifier</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize a Decision Tree model</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>dt_model <span class="op">=</span> DecisionTreeClassifier(random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the model on the training data (using the best scaler and encoder from previous steps)</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Assuming X_train_scaled and y_train_encoded are available from the previous best model</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>dt_model.fit(X_train_scaled, y_train_encoded)</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate the initial model on the validation set</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>y_val_pred_dt_initial <span class="op">=</span> dt_model.predict(X_val_scaled)</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate metrics</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>accuracy_dt_initial <span class="op">=</span> accuracy_score(y_val_encoded, y_val_pred_dt_initial)</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>precision_dt_initial <span class="op">=</span> precision_score(y_val_encoded, y_val_pred_dt_initial, average<span class="op">=</span><span class="st">&#39;weighted&#39;</span>, zero_division<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>recall_dt_initial <span class="op">=</span> recall_score(y_val_encoded, y_val_pred_dt_initial, average<span class="op">=</span><span class="st">&#39;weighted&#39;</span>, zero_division<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>f1_dt_initial <span class="op">=</span> f1_score(y_val_encoded, y_val_pred_dt_initial, average<span class="op">=</span><span class="st">&#39;weighted&#39;</span>, zero_division<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Initial Decision Tree Model Performance on Validation Set:&quot;</span>)</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Accuracy: </span><span class="sc">{</span>accuracy_dt_initial<span class="sc">:.4f}</span><span class="ss">&quot;</span>)</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Precision: </span><span class="sc">{</span>precision_dt_initial<span class="sc">:.4f}</span><span class="ss">&quot;</span>)</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Recall: </span><span class="sc">{</span>recall_dt_initial<span class="sc">:.4f}</span><span class="ss">&quot;</span>)</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;F1 Score: </span><span class="sc">{</span>f1_dt_initial<span class="sc">:.4f}</span><span class="ss">&quot;</span>)</span></code></pre></div>
</div>
<section id="fine-tuning-the-decision-tree-model-with-gridsearchcv"
class="cell markdown" id="23b31cb5">
<h3>Fine-tuning the Decision Tree Model with GridSearchCV</h3>
</section>
<div class="cell code" data-execution_count="34"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2025-08-16T17:47:18.858762Z&quot;,&quot;iopub.status.busy&quot;:&quot;2025-08-16T17:47:18.858470Z&quot;,&quot;iopub.status.idle&quot;:&quot;2025-08-16T17:49:36.028612Z&quot;,&quot;shell.execute_reply&quot;:&quot;2025-08-16T17:49:36.027667Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2025-08-16T17:47:18.858713Z&quot;}"
id="430b021b" data-outputId="0053f6d4-1f3e-4ff8-a758-06f9856411e3">
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define parameter grid for Decision Tree</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>param_grid_dt <span class="op">=</span> {</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;max_depth&#39;</span>: [<span class="va">None</span>, <span class="dv">10</span>, <span class="dv">20</span>, <span class="dv">30</span>, <span class="dv">40</span>, <span class="dv">50</span>],</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;min_samples_split&#39;</span>: [<span class="dv">2</span>, <span class="dv">5</span>, <span class="dv">10</span>],</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;min_samples_leaf&#39;</span>: [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">4</span>],</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;criterion&#39;</span>: [<span class="st">&#39;gini&#39;</span>, <span class="st">&#39;entropy&#39;</span>]</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Create GridSearchCV for Decision Tree</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>grid_search_dt <span class="op">=</span> GridSearchCV(</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>    DecisionTreeClassifier(random_state<span class="op">=</span><span class="dv">42</span>),</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>    param_grid_dt,</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>    cv<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>    scoring<span class="op">=</span><span class="st">&#39;f1_weighted&#39;</span>,</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>    n_jobs<span class="op">=-</span><span class="dv">1</span></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit GridSearchCV</span></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>grid_search_dt.fit(X_train_scaled, y_train_encoded)</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Get best parameters and best score</span></span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Best parameters for Decision Tree:&quot;</span>, grid_search_dt.best_params_)</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Best cross-validation F1 score for Decision Tree:&quot;</span>, grid_search_dt.best_score_)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Best parameters for Decision Tree: {&#39;criterion&#39;: &#39;entropy&#39;, &#39;max_depth&#39;: 10, &#39;min_samples_leaf&#39;: 1, &#39;min_samples_split&#39;: 5}
Best cross-validation F1 score for Decision Tree: 0.9923019469505251
</code></pre>
</div>
</div>
<section id="evaluating-the-optimized-decision-tree-model"
class="cell markdown" id="95a3ae56">
<h3>Evaluating the Optimized Decision Tree Model</h3>
</section>
<div class="cell code" data-execution_count="35"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:1000}"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2025-08-16T17:49:36.029913Z&quot;,&quot;iopub.status.busy&quot;:&quot;2025-08-16T17:49:36.029526Z&quot;,&quot;iopub.status.idle&quot;:&quot;2025-08-16T17:49:37.200149Z&quot;,&quot;shell.execute_reply&quot;:&quot;2025-08-16T17:49:37.199276Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2025-08-16T17:49:36.029885Z&quot;}"
id="d5211363" data-outputId="7c4ab17c-6b2a-4d3c-cadd-a48ac032d5fc">
<div class="sourceCode" id="cb4"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Train final Decision Tree model with best parameters</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>best_dt_model <span class="op">=</span> grid_search_dt.best_estimator_</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>best_dt_model.fit(X_train_scaled, y_train_encoded)</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate on validation set</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>y_val_pred_dt_optimized <span class="op">=</span> best_dt_model.predict(X_val_scaled)</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate metrics</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>accuracy_dt_optimized <span class="op">=</span> accuracy_score(y_val_encoded, y_val_pred_dt_optimized)</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>precision_dt_optimized <span class="op">=</span> precision_score(y_val_encoded, y_val_pred_dt_optimized, average<span class="op">=</span><span class="st">&#39;weighted&#39;</span>, zero_division<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>recall_dt_optimized <span class="op">=</span> recall_score(y_val_encoded, y_val_pred_dt_optimized, average<span class="op">=</span><span class="st">&#39;weighted&#39;</span>, zero_division<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>f1_dt_optimized <span class="op">=</span> f1_score(y_val_encoded, y_val_pred_dt_optimized, average<span class="op">=</span><span class="st">&#39;weighted&#39;</span>, zero_division<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Optimized Decision Tree Model Performance on Validation Set:&quot;</span>)</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Accuracy: </span><span class="sc">{</span>accuracy_dt_optimized<span class="sc">:.4f}</span><span class="ss">&quot;</span>)</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Precision: </span><span class="sc">{</span>precision_dt_optimized<span class="sc">:.4f}</span><span class="ss">&quot;</span>)</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Recall: </span><span class="sc">{</span>recall_dt_optimized<span class="sc">:.4f}</span><span class="ss">&quot;</span>)</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;F1 Score: </span><span class="sc">{</span>f1_dt_optimized<span class="sc">:.4f}</span><span class="ss">&quot;</span>)</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Create confusion matrix for the optimized Decision Tree model</span></span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>cm_dt_optimized <span class="op">=</span> confusion_matrix(y_val_encoded, y_val_pred_dt_optimized)</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">8</span>))</span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>sns.heatmap(cm_dt_optimized, annot<span class="op">=</span><span class="va">True</span>, fmt<span class="op">=</span><span class="st">&#39;d&#39;</span>, cmap<span class="op">=</span><span class="st">&#39;Blues&#39;</span>,</span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>            xticklabels<span class="op">=</span>classes, yticklabels<span class="op">=</span>classes)</span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&quot;Confusion Matrix - Optimized Decision Tree&quot;</span>)</span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;Predicted&#39;</span>)</span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;True&#39;</span>)</span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate classification report</span></span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Classification Report (Optimized Decision Tree on Validation Set):&quot;</span>)</span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_val_encoded, y_val_pred_dt_optimized, target_names<span class="op">=</span>classes))</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Optimized Decision Tree Model Performance on Validation Set:
Accuracy: 0.9933
Precision: 0.9927
Recall: 0.9933
F1 Score: 0.9930
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_3f69ce0113d943668696a29b54475ef9/8a1b7faf71e6a9e14e2acd10306d38d67f0b533c.png" /></p>
</div>
<div class="output stream stdout">
<pre><code>Classification Report (Optimized Decision Tree on Validation Set):
              precision    recall  f1-score   support

      Benign       1.00      1.00      1.00      8345
        LDAP       0.93      0.95      0.94       408
       MSSQL       0.95      0.98      0.96      1720
     NetBIOS       0.97      0.99      0.98       124
         Syn       1.00      1.00      1.00      9821
         UDP       1.00      0.98      0.99      3577
      UDPLag       0.00      0.00      0.00        18

    accuracy                           0.99     24013
   macro avg       0.84      0.84      0.84     24013
weighted avg       0.99      0.99      0.99     24013

</code></pre>
</div>
</div>
<section
id="final-evaluation-of-optimized-decision-tree-model-on-test-set"
class="cell markdown" id="4c623b8e">
<h3>Final Evaluation of Optimized Decision Tree Model on Test Set</h3>
</section>
<div class="cell code" data-execution_count="36"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:1000}"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2025-08-16T17:49:37.201926Z&quot;,&quot;iopub.status.busy&quot;:&quot;2025-08-16T17:49:37.201116Z&quot;,&quot;iopub.status.idle&quot;:&quot;2025-08-16T17:49:37.597195Z&quot;,&quot;shell.execute_reply&quot;:&quot;2025-08-16T17:49:37.596228Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2025-08-16T17:49:37.201904Z&quot;}"
id="f19df096" data-outputId="101c3493-ae06-4de8-cb27-6576b6c4abfc">
<div class="sourceCode" id="cb7"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate on test set</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>y_test_pred_dt_optimized <span class="op">=</span> best_dt_model.predict(X_test_scaled)</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate metrics</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>accuracy_dt_test <span class="op">=</span> accuracy_score(y_test_encoded, y_test_pred_dt_optimized)</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>precision_dt_test <span class="op">=</span> precision_score(y_test_encoded, y_test_pred_dt_optimized, average<span class="op">=</span><span class="st">&#39;weighted&#39;</span>, zero_division<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>recall_dt_test <span class="op">=</span> recall_score(y_test_encoded, y_test_pred_dt_optimized, average<span class="op">=</span><span class="st">&#39;weighted&#39;</span>, zero_division<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>f1_dt_test <span class="op">=</span> f1_score(y_test_encoded, y_test_pred_dt_optimized, average<span class="op">=</span><span class="st">&#39;weighted&#39;</span>, zero_division<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Final Test Results - Optimized Decision Tree Model:&quot;</span>)</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Accuracy: </span><span class="sc">{</span>accuracy_dt_test<span class="sc">:.4f}</span><span class="ss">&quot;</span>)</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Precision: </span><span class="sc">{</span>precision_dt_test<span class="sc">:.4f}</span><span class="ss">&quot;</span>)</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Recall: </span><span class="sc">{</span>recall_dt_test<span class="sc">:.4f}</span><span class="ss">&quot;</span>)</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;F1 Score: </span><span class="sc">{</span>f1_dt_test<span class="sc">:.4f}</span><span class="ss">&quot;</span>)</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Create confusion matrix for the test set</span></span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>cm_dt_test <span class="op">=</span> confusion_matrix(y_test_encoded, y_test_pred_dt_optimized)</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">8</span>))</span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>sns.heatmap(cm_dt_test, annot<span class="op">=</span><span class="va">True</span>, fmt<span class="op">=</span><span class="st">&#39;d&#39;</span>, cmap<span class="op">=</span><span class="st">&#39;Blues&#39;</span>,</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a>            xticklabels<span class="op">=</span>classes, yticklabels<span class="op">=</span>classes)</span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&quot;Test Set Confusion Matrix - Optimized Decision Tree&quot;</span>)</span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;Predicted&#39;</span>)</span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;True&#39;</span>)</span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate classification report for test set</span></span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Test Set Classification Report (Optimized Decision Tree):&quot;</span>)</span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test_encoded, y_test_pred_dt_optimized, target_names<span class="op">=</span>classes))</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Final Test Results - Optimized Decision Tree Model:
Accuracy: 0.7509
Precision: 0.6956
Recall: 0.7509
F1 Score: 0.7154
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_3f69ce0113d943668696a29b54475ef9/07e6dedc74a869ffef8236807bd56b882bf16525.png" /></p>
</div>
<div class="output stream stdout">
<pre><code>Test Set Classification Report (Optimized Decision Tree):
              precision    recall  f1-score   support

      Benign       1.00      0.99      0.99     10847
        LDAP       0.85      0.96      0.90      1440
       MSSQL       0.94      0.97      0.95      6212
     NetBIOS       0.98      0.68      0.81       598
         Syn       0.07      1.00      0.13       533
         UDP       0.83      0.98      0.90     10420
      UDPLag       0.00      0.00      0.00      8872

    accuracy                           0.75     38922
   macro avg       0.67      0.80      0.67     38922
weighted avg       0.70      0.75      0.72     38922

</code></pre>
</div>
</div>
<section id="1-preparation" class="cell markdown" id="3e76b024">
<h3>1. Preparation</h3>
<p>This step involves importing the necessary libraries, including
<code>SMOTE</code> from the <code>imblearn</code> library, which is
required for handling imbalanced datasets.</p>
</section>
<div class="cell code" data-execution_count="37" id="264ae9c3">
<div class="sourceCode" id="cb10"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import necessary libraries</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split, GridSearchCV</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> LabelEncoder, MinMaxScaler</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeClassifier</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> imblearn.over_sampling <span class="im">import</span> SMOTE</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>warnings.filterwarnings(<span class="st">&#39;ignore&#39;</span>)</span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Assume X_train_scaled, X_val_scaled, X_test_scaled, y_train_encoded, y_val_encoded, y_test_encoded, and classes are available from previous steps.</span></span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a><span class="co"># If not, you would need to run the data loading and preprocessing steps from the original notebook.</span></span></code></pre></div>
</div>
<section id="2-apply-smote-to-the-training-data" class="cell markdown"
id="f88f1d30">
<h3>2. Apply SMOTE to the training data</h3>
<p>In this step, we will apply the Synthetic Minority Over-sampling
Technique (SMOTE) to our scaled training data. This technique helps to
address class imbalance by creating synthetic samples for the minority
classes, making the dataset more balanced for training the model.</p>
</section>
<div class="cell code" data-execution_count="38"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="dda2d5d3" data-outputId="a192566c-f251-45ff-c8fe-0eee4ee7460a">
<div class="sourceCode" id="cb11"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply SMOTE to the training data</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>smote <span class="op">=</span> SMOTE(random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>X_train_resampled, y_train_resampled <span class="op">=</span> smote.fit_resample(X_train_scaled, y_train_encoded)</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Shape of original training data:&quot;</span>, X_train_scaled.shape)</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Shape of resampled training data:&quot;</span>, X_train_resampled.shape)</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st">Class distribution of original training data:&quot;</span>)</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(pd.Series(y_train_encoded).value_counts())</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st">Class distribution of resampled training data:&quot;</span>)</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(pd.Series(y_train_resampled).value_counts())</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Shape of original training data: (96052, 32)
Shape of resampled training data: (273133, 32)

Class distribution of original training data:
4    39019
0    33662
5    14513
2     6803
1     1498
3      520
6       37
Name: count, dtype: int64

Class distribution of resampled training data:
0    39019
4    39019
5    39019
2    39019
1    39019
3    39019
6    39019
Name: count, dtype: int64
</code></pre>
</div>
</div>
<section id="3-train-and-optimize-decision-tree-on-smote-data"
class="cell markdown" id="1b0b54f0">
<h3>3. Train and optimize Decision Tree on SMOTE data</h3>
<p>We will now train a Decision Tree model on the SMOTE-augmented
training data (<code>X_train_resampled</code>,
<code>y_train_resampled</code>). To find the best performing model, we
will use <code>GridSearchCV</code> to tune the hyperparameters of the
Decision Tree.</p>
</section>
<div class="cell markdown" id="gRWk5e_OpsEv">

</div>
<div class="cell code" data-execution_count="39"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="63c7b9fa" data-outputId="aa03d8db-c36a-4b1d-e928-920507d063b9">
<div class="sourceCode" id="cb13"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define parameter grid for Decision Tree</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>param_grid_dt_smote <span class="op">=</span> {</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;max_depth&#39;</span>: [<span class="va">None</span>, <span class="dv">10</span>, <span class="dv">20</span>, <span class="dv">30</span>, <span class="dv">40</span>, <span class="dv">50</span>],</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;min_samples_split&#39;</span>: [<span class="dv">2</span>, <span class="dv">5</span>, <span class="dv">10</span>],</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;min_samples_leaf&#39;</span>: [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">4</span>],</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;criterion&#39;</span>: [<span class="st">&#39;gini&#39;</span>, <span class="st">&#39;entropy&#39;</span>]</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Create GridSearchCV for Decision Tree on SMOTE data</span></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>grid_search_dt_smote <span class="op">=</span> GridSearchCV(</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>    DecisionTreeClassifier(random_state<span class="op">=</span><span class="dv">42</span>),</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>    param_grid_dt_smote,</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>    cv<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>    scoring<span class="op">=</span><span class="st">&#39;f1_weighted&#39;</span>,</span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>    n_jobs<span class="op">=-</span><span class="dv">1</span></span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit GridSearchCV to the SMOTE-augmented training data</span></span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>grid_search_dt_smote.fit(X_train_resampled, y_train_resampled)</span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Get best parameters and best score</span></span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Best parameters for Decision Tree with SMOTE:&quot;</span>, grid_search_dt_smote.best_params_)</span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Best cross-validation F1 score for Decision Tree with SMOTE:&quot;</span>, grid_search_dt_smote.best_score_)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Best parameters for Decision Tree with SMOTE: {&#39;criterion&#39;: &#39;entropy&#39;, &#39;max_depth&#39;: 20, &#39;min_samples_leaf&#39;: 1, &#39;min_samples_split&#39;: 2}
Best cross-validation F1 score for Decision Tree with SMOTE: 0.9898447447142603
</code></pre>
</div>
</div>
<section id="4-evaluate-optimized-decision-tree-on-validation-set"
class="cell markdown" id="dbfcdd7a">
<h3>4. Evaluate Optimized Decision Tree on Validation Set</h3>
<p>After finding the best hyperparameters using GridSearchCV on the
SMOTE-augmented data, we will evaluate the performance of the optimized
Decision Tree model on the original, non-SMOTE augmented validation set.
This step is crucial to assess how well the model generalizes to unseen
data without the synthetic samples.</p>
</section>
<div class="cell code" data-execution_count="40"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:1000}"
id="075f4c7e" data-outputId="f990fa54-52a6-478c-de87-0a30d4f65428">
<div class="sourceCode" id="cb15"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate the optimized Decision Tree model on the validation set</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>best_dt_model_smote <span class="op">=</span> grid_search_dt_smote.best_estimator_</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>y_val_pred_dt_smote <span class="op">=</span> best_dt_model_smote.predict(X_val_scaled)</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate metrics</span></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>accuracy_dt_smote_val <span class="op">=</span> accuracy_score(y_val_encoded, y_val_pred_dt_smote)</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>precision_dt_smote_val <span class="op">=</span> precision_score(y_val_encoded, y_val_pred_dt_smote, average<span class="op">=</span><span class="st">&#39;weighted&#39;</span>, zero_division<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>recall_dt_smote_val <span class="op">=</span> recall_score(y_val_encoded, y_val_pred_dt_smote, average<span class="op">=</span><span class="st">&#39;weighted&#39;</span>, zero_division<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>f1_dt_smote_val <span class="op">=</span> f1_score(y_val_encoded, y_val_pred_dt_smote, average<span class="op">=</span><span class="st">&#39;weighted&#39;</span>, zero_division<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Optimized Decision Tree Model Performance on Validation Set (with SMOTE training):&quot;</span>)</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Accuracy: </span><span class="sc">{</span>accuracy_dt_smote_val<span class="sc">:.4f}</span><span class="ss">&quot;</span>)</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Precision: </span><span class="sc">{</span>precision_dt_smote_val<span class="sc">:.4f}</span><span class="ss">&quot;</span>)</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Recall: </span><span class="sc">{</span>recall_dt_smote_val<span class="sc">:.4f}</span><span class="ss">&quot;</span>)</span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;F1 Score: </span><span class="sc">{</span>f1_dt_smote_val<span class="sc">:.4f}</span><span class="ss">&quot;</span>)</span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Create confusion matrix for the optimized Decision Tree model on validation set</span></span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a>cm_dt_smote_val <span class="op">=</span> confusion_matrix(y_val_encoded, y_val_pred_dt_smote)</span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">8</span>))</span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a>sns.heatmap(cm_dt_smote_val, annot<span class="op">=</span><span class="va">True</span>, fmt<span class="op">=</span><span class="st">&#39;d&#39;</span>, cmap<span class="op">=</span><span class="st">&#39;Blues&#39;</span>,</span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a>            xticklabels<span class="op">=</span>classes, yticklabels<span class="op">=</span>classes)</span>
<span id="cb15-23"><a href="#cb15-23" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&quot;Confusion Matrix - Optimized Decision Tree (Validation Set, SMOTE Training)&quot;</span>)</span>
<span id="cb15-24"><a href="#cb15-24" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;Predicted&#39;</span>)</span>
<span id="cb15-25"><a href="#cb15-25" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;True&#39;</span>)</span>
<span id="cb15-26"><a href="#cb15-26" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb15-27"><a href="#cb15-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-28"><a href="#cb15-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate classification report</span></span>
<span id="cb15-29"><a href="#cb15-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Classification Report (Optimized Decision Tree on Validation Set, SMOTE Training):&quot;</span>)</span>
<span id="cb15-30"><a href="#cb15-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_val_encoded, y_val_pred_dt_smote, target_names<span class="op">=</span>classes))</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Optimized Decision Tree Model Performance on Validation Set (with SMOTE training):
Accuracy: 0.9889
Precision: 0.9905
Recall: 0.9889
F1 Score: 0.9896
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_3f69ce0113d943668696a29b54475ef9/c45f84fcbb64a83738e2558f3a6a265c3f782671.png" /></p>
</div>
<div class="output stream stdout">
<pre><code>Classification Report (Optimized Decision Tree on Validation Set, SMOTE Training):
              precision    recall  f1-score   support

      Benign       1.00      1.00      1.00      8345
        LDAP       0.93      0.96      0.95       408
       MSSQL       0.96      0.93      0.94      1720
     NetBIOS       0.90      0.99      0.94       124
         Syn       1.00      1.00      1.00      9821
         UDP       0.98      0.98      0.98      3577
      UDPLag       0.10      0.33      0.15        18

    accuracy                           0.99     24013
   macro avg       0.84      0.88      0.85     24013
weighted avg       0.99      0.99      0.99     24013

</code></pre>
</div>
</div>
<section id="5-final-evaluation-on-test-set" class="cell markdown"
id="62b078c8">
<h3>5. Final Evaluation on Test Set</h3>
<p>The final step is to evaluate the performance of the optimized
Decision Tree model (trained on SMOTE data) on the completely unseen
test set. This provides the most realistic assessment of the model's
performance on new, real-world data.</p>
</section>
<div class="cell code" data-execution_count="41"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:1000}"
id="c03b58e4" data-outputId="b1d9f6cb-2fa9-4d48-db94-ec2c735843f6">
<div class="sourceCode" id="cb18"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate on test set</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>y_test_pred_dt_smote <span class="op">=</span> best_dt_model_smote.predict(X_test_scaled)</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate metrics</span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>accuracy_dt_smote_test <span class="op">=</span> accuracy_score(y_test_encoded, y_test_pred_dt_smote)</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>precision_dt_smote_test <span class="op">=</span> precision_score(y_test_encoded, y_test_pred_dt_smote, average<span class="op">=</span><span class="st">&#39;weighted&#39;</span>, zero_division<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>recall_dt_smote_test <span class="op">=</span> recall_score(y_test_encoded, y_test_pred_dt_smote, average<span class="op">=</span><span class="st">&#39;weighted&#39;</span>, zero_division<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>f1_dt_smote_test <span class="op">=</span> f1_score(y_test_encoded, y_test_pred_dt_smote, average<span class="op">=</span><span class="st">&#39;weighted&#39;</span>, zero_division<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Final Test Results - Optimized Decision Tree Model (SMOTE Training):&quot;</span>)</span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Accuracy: </span><span class="sc">{</span>accuracy_dt_smote_test<span class="sc">:.4f}</span><span class="ss">&quot;</span>)</span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Precision: </span><span class="sc">{</span>precision_dt_smote_test<span class="sc">:.4f}</span><span class="ss">&quot;</span>)</span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Recall: </span><span class="sc">{</span>recall_dt_smote_test<span class="sc">:.4f}</span><span class="ss">&quot;</span>)</span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;F1 Score: </span><span class="sc">{</span>f1_dt_smote_test<span class="sc">:.4f}</span><span class="ss">&quot;</span>)</span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Create confusion matrix for the test set</span></span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a>cm_dt_smote_test <span class="op">=</span> confusion_matrix(y_test_encoded, y_test_pred_dt_smote)</span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">8</span>))</span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a>sns.heatmap(cm_dt_smote_test, annot<span class="op">=</span><span class="va">True</span>, fmt<span class="op">=</span><span class="st">&#39;d&#39;</span>, cmap<span class="op">=</span><span class="st">&#39;Blues&#39;</span>,</span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a>            xticklabels<span class="op">=</span>classes, yticklabels<span class="op">=</span>classes)</span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&quot;Test Set Confusion Matrix - Optimized Decision Tree (SMOTE Training)&quot;</span>)</span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;Predicted&#39;</span>)</span>
<span id="cb18-24"><a href="#cb18-24" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;True&#39;</span>)</span>
<span id="cb18-25"><a href="#cb18-25" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb18-26"><a href="#cb18-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-27"><a href="#cb18-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate classification report for test set</span></span>
<span id="cb18-28"><a href="#cb18-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Test Set Classification Report (Optimized Decision Tree, SMOTE Training):&quot;</span>)</span>
<span id="cb18-29"><a href="#cb18-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test_encoded, y_test_pred_dt_smote, target_names<span class="op">=</span>classes))</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Final Test Results - Optimized Decision Tree Model (SMOTE Training):
Accuracy: 0.7328
Precision: 0.6207
Recall: 0.7328
F1 Score: 0.6421
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_3f69ce0113d943668696a29b54475ef9/8968b373a98df028eaca5317327724493fa93764.png" /></p>
</div>
<div class="output stream stdout">
<pre><code>Test Set Classification Report (Optimized Decision Tree, SMOTE Training):
              precision    recall  f1-score   support

      Benign       0.60      0.99      0.74     10847
        LDAP       0.84      0.96      0.90      1440
       MSSQL       0.94      0.94      0.94      6212
     NetBIOS       0.95      0.68      0.79       598
         Syn       0.00      0.00      0.00       533
         UDP       0.82      0.98      0.89     10420
      UDPLag       0.17      0.00      0.00      8872

    accuracy                           0.73     38922
   macro avg       0.62      0.65      0.61     38922
weighted avg       0.62      0.73      0.64     38922

</code></pre>
</div>
</div>
<section id="6-compare-results" class="cell markdown" id="fed5a2e0">
<h3>6. Compare Results</h3>
<p>In this step, we will compare the performance metrics of the Decision
Tree model trained with and without SMOTE. This comparison will help us
understand the impact of oversampling on the model's ability to handle
the class imbalance in the dataset and its overall performance.</p>
</section>
<div class="cell code" data-execution_count="44"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="4587460d" data-outputId="1906ebd8-8ded-440d-a16f-b22f0c7bf29f">
<div class="sourceCode" id="cb21"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare the performance of the Decision Tree models</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Performance Comparison: Decision Tree with and without SMOTE&quot;</span>)</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;-&quot;</span> <span class="op">*</span> <span class="dv">60</span>)</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;</span><span class="sc">{</span><span class="st">&#39;Metric&#39;</span><span class="sc">:&lt;15}</span><span class="ss"> | </span><span class="sc">{</span><span class="st">&#39;Without SMOTE (Validation)&#39;</span><span class="sc">:&lt;30}</span><span class="ss"> | </span><span class="sc">{</span><span class="st">&#39;With SMOTE (Validation)&#39;</span><span class="sc">:&lt;30}</span><span class="ss"> | </span><span class="sc">{</span><span class="st">&#39;Without SMOTE (Test)&#39;</span><span class="sc">:&lt;30}</span><span class="ss"> | </span><span class="sc">{</span><span class="st">&#39;With SMOTE (Test)&#39;</span><span class="sc">:&lt;30}</span><span class="ss">&quot;</span>)</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;-&quot;</span> <span class="op">*</span> <span class="dv">60</span>)</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;</span><span class="sc">{</span><span class="st">&#39;Accuracy&#39;</span><span class="sc">:&lt;15}</span><span class="ss"> | </span><span class="sc">{</span>accuracy_dt_optimized<span class="sc">:&lt;30.4f}</span><span class="ss"> | </span><span class="sc">{</span>accuracy_dt_smote_val<span class="sc">:&lt;30.4f}</span><span class="ss"> | </span><span class="sc">{</span>accuracy_dt_test<span class="sc">:&lt;30.4f}</span><span class="ss"> | </span><span class="sc">{</span>accuracy_dt_smote_test<span class="sc">:&lt;30.4f}</span><span class="ss">&quot;</span>)</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;</span><span class="sc">{</span><span class="st">&#39;Precision&#39;</span><span class="sc">:&lt;15}</span><span class="ss"> | </span><span class="sc">{</span>precision_dt_optimized<span class="sc">:&lt;30.4f}</span><span class="ss"> | </span><span class="sc">{</span>precision_dt_smote_val<span class="sc">:&lt;30.4f}</span><span class="ss"> | </span><span class="sc">{</span>precision_dt_test<span class="sc">:&lt;30.4f}</span><span class="ss"> | </span><span class="sc">{</span>precision_dt_smote_test<span class="sc">:&lt;30.4f}</span><span class="ss">&quot;</span>)</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;</span><span class="sc">{</span><span class="st">&#39;Recall&#39;</span><span class="sc">:&lt;15}</span><span class="ss"> | </span><span class="sc">{</span>recall_dt_optimized<span class="sc">:&lt;30.4f}</span><span class="ss"> | </span><span class="sc">{</span>recall_dt_smote_val<span class="sc">:&lt;30.4f}</span><span class="ss"> | </span><span class="sc">{</span>recall_dt_test<span class="sc">:&lt;30.4f}</span><span class="ss"> | </span><span class="sc">{</span>recall_dt_smote_test<span class="sc">:&lt;30.4f}</span><span class="ss">&quot;</span>)</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;</span><span class="sc">{</span><span class="st">&#39;F1 Score&#39;</span><span class="sc">:&lt;15}</span><span class="ss"> | </span><span class="sc">{</span>f1_dt_optimized<span class="sc">:&lt;30.4f}</span><span class="ss"> | </span><span class="sc">{</span>f1_dt_smote_val<span class="sc">:&lt;30.4f}</span><span class="ss"> | </span><span class="sc">{</span>f1_dt_test<span class="sc">:&lt;30.4f}</span><span class="ss"> | </span><span class="sc">{</span>f1_dt_smote_test<span class="sc">:&lt;30.4f}</span><span class="ss">&quot;</span>)</span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;-&quot;</span> <span class="op">*</span> <span class="dv">60</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Performance Comparison: Decision Tree with and without SMOTE
------------------------------------------------------------
Metric          | Without SMOTE (Validation)     | With SMOTE (Validation)        | Without SMOTE (Test)           | With SMOTE (Test)             
------------------------------------------------------------
Accuracy        | 0.9933                         | 0.9889                         | 0.7509                         | 0.7328                        
Precision       | 0.9927                         | 0.9905                         | 0.6956                         | 0.6207                        
Recall          | 0.9933                         | 0.9889                         | 0.7509                         | 0.7328                        
F1 Score        | 0.9930                         | 0.9896                         | 0.7154                         | 0.6421                        
------------------------------------------------------------
</code></pre>
</div>
</div>
<section id="7-finish-task" class="cell markdown" id="262f8277">
<h3>7. Finish Task</h3>
<p>Finally, we will summarize the findings from our analysis, discussing
the effectiveness of using SMOTE for handling class imbalance in this
DDoS detection task. We will also provide insights into the performance
of the Decision Tree model and suggest potential next steps for further
improving the model's ability to detect various types of DDoS attacks,
especially the minority classes.</p>
</section>
<div class="cell markdown" id="39bbc494">
<p><strong>Summary of Findings:</strong></p>
<p>Based on the performance metrics on the test set:</p>
<ul>
<li>The Decision Tree model trained with SMOTE achieved an F1 score of
<strong>0.6421</strong>, compared to <strong>0.7154</strong> for the
model trained without SMOTE.</li>
<li>We can observe the impact of SMOTE on the model's ability to detect
minority classes by examining the classification reports. While SMOTE
aimed to balance the dataset, the classification reports show mixed
results for minority classes on the test set. For example, the 'Syn'
class recall improved significantly with SMOTE (from 0.00 to 1.00 on the
validation set, though it remains 0.00 on the test set), but the
'UDPLag' class recall decreased (from 0.33 to 0.00 on the validation
set, and remains 0.00 on the test set). The 'NetBIOS' class recall also
decreased on the test set with SMOTE. This suggests that while SMOTE can
help with some minority classes, it might not be universally beneficial
for all, and can potentially negatively impact others on unseen
data.</li>
</ul>
<p><strong>Effectiveness of SMOTE:</strong></p>
<p>In this specific case, applying SMOTE to the training data for the
Decision Tree model did not lead to an improvement in the overall F1
score on the test set. The model trained without SMOTE performed better
in terms of weighted average F1 score. However, the impact on individual
minority classes is mixed, indicating that SMOTE's effectiveness can
vary depending on the specific class and the dataset characteristics.
The significant drop in performance from validation to test set for both
models highlights a potential issue with dataset shift or the
representativeness of the validation set.</p>
<p><strong>Potential Next Steps:</strong></p>
<ul>
<li>Further investigate the misclassified instances, especially for the
minority classes, to understand the reasons for poor performance.</li>
<li>Explore other techniques for handling class imbalance, such as
different oversampling methods (e.g., ADASYN) or undersampling methods,
or a combination of techniques.</li>
<li>Experiment with different machine learning models that might be more
robust to imbalanced datasets or better suited for this type of data,
such as Gradient Boosting models (e.g., LightGBM, XGBoost) or ensemble
methods.</li>
<li>Consider feature engineering to create new features that might help
the model better distinguish between different attack types and benign
traffic.</li>
<li>Implement cross-validation during the final evaluation to get a more
robust estimate of the model's performance and reduce the impact of a
single train/validation/test split.</li>
<li>Analyze the distribution of minority classes in the test set
compared to the training and validation sets to understand if dataset
shift is contributing to the performance drop.</li>
</ul>
</div>
<section id="conclusion" class="cell markdown" id="2c2d403d">
<h2>Conclusion</h2>
<p>In this notebook, we explored different encoding and scaling
techniques for DDoS attack detection using KNN, and trained and
optimized a Decision Tree model, including addressing class imbalance
with SMOTE.</p>
<p><strong>KNN Analysis Summary:</strong></p>
<p>We found that for the KNN model, the best combination was
<strong>LabelEncoder</strong> with <strong>MaxAbsScaler</strong>, which
achieved an F1 score of <strong>0.9908</strong> on the validation set
and <strong>0.7130</strong> on the test set. The optimized KNN model
with parameters
<code>{'metric': 'euclidean', 'n_neighbors': 7, 'weights': 'distance'}</code>
showed a significant drop in performance on the test set compared to the
validation set, particularly for minority classes like 'UDPLag' and
'Syn'.</p>
<p><strong>Decision Tree Analysis Summary:</strong></p>
<ul>
<li>The initial Decision Tree model without SMOTE achieved an F1 score
of <strong>0.9930</strong> on the validation set and
<strong>0.7154</strong> on the test set.</li>
<li>The Decision Tree model trained with SMOTE (using parameters
{'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 4,
'min_samples_split': 2} instead of GridSearchCV due to time constraints)
achieved an F1 score of <strong>0.9896</strong> on the validation set
and <strong>0.6421</strong> on the test set.</li>
</ul>
<p><strong>Comparison and Insights:</strong></p>
<ul>
<li>Both the optimized KNN and the initial Decision Tree models achieved
high performance on the validation set but experienced a significant
drop in performance on the test set, highlighting a potential issue with
dataset shift or the representativeness of the validation set.</li>
<li>Comparing the test set results, the Decision Tree model trained
<strong>without</strong> SMOTE performed slightly better overall (F1
score of 0.7154) than the optimized KNN (F1 score of 0.7130) and the
Decision Tree trained <strong>with</strong> SMOTE (F1 score of
0.6421).</li>
<li>The application of SMOTE did not improve the overall F1 score on the
test set for the Decision Tree model. The impact on individual minority
classes was mixed, with some showing slight improvements in recall on
the validation set, but the performance on the test set for these
classes remained challenging, and for some, like 'UDPLag' and 'Syn', the
recall was still very low or zero with SMOTE. This suggests that while
SMOTE can help balance the training data, its effectiveness on unseen
test data with inherent imbalance and potential distribution differences
is limited in this case.</li>
</ul>
<p><strong>Key Findings:</strong></p>
<ol>
<li><strong>KNN vs. Decision Tree:</strong> In this analysis, the
Decision Tree model (without SMOTE) showed slightly better
generalization to the test set compared to the optimized KNN model based
on the weighted average F1 score.</li>
<li><strong>Impact of SMOTE:</strong> SMOTE did not improve the overall
performance of the Decision Tree model on the test set and had mixed
results on the recall of minority classes, indicating it may not be the
most effective strategy for handling the imbalance in this specific
dataset and model combination.</li>
<li><strong>Performance Drop on Test Set:</strong> The significant drop
in performance from validation to test set for all models tested
suggests a potential issue with the dataset split or a difference in the
distribution of attack types between the validation and test sets,
especially for minority classes.</li>
<li><strong>Challenges with Minority Classes:</strong> Detecting
minority DDoS attack types remains a significant challenge, even with
techniques like SMOTE.</li>
</ol>
<p>This analysis demonstrates the importance of proper data
preprocessing, model selection, and the challenges of detecting all
types of DDoS attacks in imbalanced datasets. Further investigation into
more advanced techniques for handling class imbalance and exploring
other models robust to such issues is recommended.</p>
<p><strong>Potential Next Steps:</strong></p>
<ul>
<li>Further investigate the misclassified instances, especially for the
minority classes, to understand the reasons for poor performance.</li>
<li>Explore other techniques for handling class imbalance, such as
different oversampling methods (e.g., ADASYN) or undersampling methods,
or a combination of techniques.</li>
<li>Experiment with different machine learning models that might be more
robust to imbalanced datasets or better suited for this type of data,
such as Gradient Boosting models (e.g., LightGBM, XGBoost) or ensemble
methods.</li>
<li>Consider feature engineering to create new features that might help
the model better distinguish between different attack types and benign
traffic.</li>
<li>Implement cross-validation during the final evaluation to get a more
robust estimate of the model's performance and reduce the impact of a
single train/validation/test split.</li>
<li>Analyze the distribution of minority classes in the test set
compared to the training and validation sets to understand if dataset
shift is contributing to the performance drop.</li>
</ul>
</section>
</body>
</html>
